# -*- coding: utf-8 -*-
"""AA_XAI_PArt 2_ResNet_Gradcam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aJDoPi2A_SOnJU6oTpOkTp7vHE36XqeL
"""

import torch
import torch.optim as optim
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import pandas as pd
import os
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix

from google.colab import drive
import os
import pandas as pd

# Mount Google Drive
drive.mount('/content/drive')

# Define the function to create dataset
def create_dataset(folder_path):
    my_list = []
    for category in ['NORMAL', 'PNEUMONIA']:  # Iterate over the two classes
        category_path = os.path.join(folder_path, category)
        if os.path.exists(category_path):  # Ensure the category folder exists
            for file_name in os.listdir(category_path):
                file_path = os.path.join(category_path, file_name)
                # Ensure we're only adding image files
                if os.path.isfile(file_path) and file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    my_list.append([file_path, category])
    return pd.DataFrame(my_list, columns=['file_path', 'label'])

# Dataset paths in Google Drive
dataset_dir = '/content/drive/My Drive/XAI_AA'  # Change this to your dataset path
train_dir = os.path.join(dataset_dir, 'train')
val_dir = os.path.join(dataset_dir, 'val')
test_dir = os.path.join(dataset_dir, 'test')

# Create DataFrames for train, validation, and test datasets
train_df = create_dataset(train_dir)
val_df = create_dataset(val_dir)
test_df = create_dataset(test_dir)

# Convert labels to numeric: NORMAL -> 0, PNEUMONIA -> 1
train_df['label'] = train_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1})
val_df['label'] = val_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1})
test_df['label'] = test_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1})

# Print dataset sizes
print(f"Train set size: {len(train_df)}, Validation set size: {len(val_df)}, Test set size: {len(test_df)}")

def count_categories(df, dataset_name):
    category_counts = df['label'].value_counts()
    print(f"{dataset_name} set:")
    print(f"  NORMAL: {category_counts.get(0, 0)}")
    print(f"  PNEUMONIA: {category_counts.get(1, 0)}")

# Count and display for train, validation, and test datasets
print("Image Counts per Category:")
count_categories(train_df, "Train")
count_categories(val_df, "Validation")
count_categories(test_df, "Test")

def visualize_samples(df, n_samples=5):
    fig, axes = plt.subplots(2, n_samples, figsize=(15, 10))

    # Visualize 5 NORMAL samples
    normal_samples = df[df['label'] == 0].iloc[:n_samples]
    for i in range(n_samples):
        img_path = normal_samples.iloc[i, 0]
        label = normal_samples.iloc[i, 1]
        image = Image.open(img_path).convert('L')  # Open in grayscale (original format)
        axes[0, i].imshow(image, cmap='gray')
        axes[0, i].set_title(f"Label: {['Normal', 'Pneumonia'][label]}")
        axes[0, i].axis('off')

    # Visualize 5 PNEUMONIA samples
    pneumonia_samples = df[df['label'] == 1].iloc[:n_samples]
    for i in range(n_samples):
        img_path = pneumonia_samples.iloc[i, 0]
        label = pneumonia_samples.iloc[i, 1]
        image = Image.open(img_path).convert('L')  # Open in grayscale (original format)
        axes[1, i].imshow(image, cmap='gray')
        axes[1, i].set_title(f"Label: {['Normal', 'Pneumonia'][label]}")
        axes[1, i].axis('off')

    plt.show()

# Show 5 samples from the training data
visualize_samples(train_df)

# Visualizing the class distribution
train_counts = train_df['label'].value_counts()
val_counts = val_df['label'].value_counts()
test_counts = test_df['label'].value_counts()

plt.figure(figsize=(8, 6))
plt.bar(['Normal', 'Pneumonia'], train_counts, color=['green','red'])
plt.title("Training Data Class Distribution")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8, 6))
plt.bar(['Normal', 'Pneumonia'], val_counts, color=['green','red'])
plt.title("Validation Data Class Distribution")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8, 6))
plt.bar(['Normal', 'Pneumonia'], test_counts, color=['green','red'])
plt.title("Test Data Class Distribution")
plt.ylabel("Count")
plt.show()

# Check for multi-GPU availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Function to prepare model for multi-GPU usage
def prepare_model_for_multigpu(model):
    if torch.cuda.device_count() > 1:
        print(f"Using {torch.cuda.device_count()} GPUs!")
        model = nn.DataParallel(model)
    model = model.to(device)
    return model



class ImageDataset(torch.utils.data.Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx, 0]
        label = self.dataframe.iloc[idx, 1]
        img = Image.open(img_path).convert('RGB')

        if self.transform:
            img = self.transform(img)

        return img, label

# Define transformations for training and validation

# For Custom CNN (Grayscale Input)
"""train_transform_cnn = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(),  # Convert to grayscale (1 channel)
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(0.2),
    transforms.ToTensor(),

])

val_transform_cnn = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(),
    transforms.ToTensor(),
])"""

# For ResNet-18 (RGB Input)
train_transform_resnet = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
])

val_transform_resnet = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)
    transforms.ToTensor(),
])

# Create datasets for both models
"""train_dataset_cnn = ImageDataset(train_df, transform=train_transform_cnn)
val_dataset_cnn = ImageDataset(val_df, transform=val_transform_cnn)"""

train_dataset_resnet = ImageDataset(train_df, transform=train_transform_resnet)
val_dataset_resnet = ImageDataset(val_df, transform=val_transform_resnet)

# DataLoader
batch_size = 32
"""train_loader_cnn = DataLoader(train_dataset_cnn, batch_size=batch_size, shuffle=True)
val_loader_cnn = DataLoader(val_dataset_cnn, batch_size=batch_size, shuffle=False)"""

train_loader_resnet = DataLoader(train_dataset_resnet, batch_size=batch_size, shuffle=True)
val_loader_resnet = DataLoader(val_dataset_resnet, batch_size=batch_size, shuffle=False)

def train_model_with_history(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        # Training loop
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        # Calculate training loss and accuracy
        train_loss = running_loss / len(train_loader)
        train_accuracy = 100 * correct / total
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)

        # Validation loop
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        # Calculate validation loss and accuracy
        val_loss = val_loss / len(val_loader)
        val_accuracy = 100 * val_correct / val_total
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        # Print results for the epoch
        print(f"Epoch [{epoch+1}/{num_epochs}] "
              f"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%")

    return train_losses, val_losses, train_accuracies, val_accuracies

# Define loss function and optimizer for Custom CNN
criterion = nn.CrossEntropyLoss()
#optimizer_from_scratch = optim.Adam(model_from_scratch.parameters(), lr=0.001)

def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies, model_name):
    epochs = range(1, len(train_losses) + 1)

    # Plot Loss
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label='Train Loss')
    plt.plot(epochs, val_losses, label='Val Loss')
    plt.title(f'{model_name} - Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accuracies, label='Train Accuracy')
    plt.plot(epochs, val_accuracies, label='Val Accuracy')
    plt.title(f'{model_name} - Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Plot results for Custom CNN (from scratch)
#plot_training_history(train_losses_cnn, val_losses_cnn, train_accuracies_cnn, val_accuracies_cnn, "Custom CNN (from scratch)")

"""LOading predefined model"""

# Load pretrained ResNet-18 model
resnet18 = models.resnet18(pretrained=True)
resnet18.fc = nn.Linear(resnet18.fc.in_features, 2)  # Modify for binary classification
resnet18 = prepare_model_for_multigpu(resnet18)  # Apply multi-GPU

# Define optimizer for ResNet-18
optimizer_resnet = optim.Adam(resnet18.parameters(), lr=0.001)

# Train the Pretrained ResNet-18 Model
print("Training Pretrained ResNet-18 Model...")
train_losses_resnet, val_losses_resnet, train_accuracies_resnet, val_accuracies_resnet = train_model_with_history(
    resnet18, train_loader_resnet, val_loader_resnet, criterion, optimizer_resnet, num_epochs=10
)

# Plot training and validation loss/accuracy for ResNet-18
plot_training_history(train_losses_resnet, val_losses_resnet, train_accuracies_resnet, val_accuracies_resnet, "Pretrained ResNet-18")

#Create Dataset and DataLoader for Test Set (ResNet-18)
test_transform_resnet = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels (RGB)
    transforms.ToTensor(),
])

test_dataset_resnet = ImageDataset(test_df, transform=test_transform_resnet)
test_loader_resnet = DataLoader(test_dataset_resnet, batch_size=32, shuffle=False)

# Function to evaluate the model and return predictions, true labels, and scores
def evaluate_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return all_labels, all_preds

# Evaluate Custom CNN from Scratch on Test Set
#y_true_cnn, y_pred_cnn = evaluate_model(model_from_scratch, test_loader_cnn)

# Evaluate Pretrained ResNet18 on Test Set
y_true_resnet, y_pred_resnet = evaluate_model(resnet18, test_loader_resnet)

# Print accuracy for both models
#accuracy_cnn = accuracy_score(y_true_cnn, y_pred_cnn)
accuracy_resnet = accuracy_score(y_true_resnet, y_pred_resnet)

#print(f"Accuracy of Custom CNN from Scratch: {accuracy_cnn:.4f}")
print(f"Accuracy of Pretrained ResNet18: {accuracy_resnet:.4f}")

# Function to plot confusion matrix with percentages
def plot_confusion_matrix_with_percentages(cm, model_name):
    plt.figure(figsize=(5, 5))
    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

    # Annotate with both raw numbers and percentages
    annot = np.empty_like(cm).astype(str)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            annot[i, j] = f"{cm[i, j]}\n({cm_percentage[i, j]:.1f}%)"

    sns.heatmap(cm, annot=annot, fmt="", cmap="Blues", xticklabels=["Normal", "Pneumonia"], yticklabels=["Normal", "Pneumonia"])
    plt.title(f"Confusion Matrix - {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

# Scores and Confusion Matrix for Custom CNN from Scratch
"""print("Custom CNN from Scratch:")
cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)
plot_confusion_matrix_with_percentages(cm_cnn, "Custom CNN from Scratch")
print("Classification Report:\n", classification_report(y_true_cnn, y_pred_cnn))"""

# Scores and Confusion Matrix for Pretrained ResNet18
print("Pretrained ResNet18:")
cm_resnet = confusion_matrix(y_true_resnet, y_pred_resnet)
plot_confusion_matrix_with_percentages(cm_resnet, "Pretrained ResNet18")
print("Classification Report:\n", classification_report(y_true_resnet, y_pred_resnet))



# Make sure to change to your own path in Google Drive
save_path = "/content/drive/My Drive/XAI_AA/resnet18_model.pth"

torch.save(resnet18.state_dict(), save_path)

def show_balanced_predictions(model, loader, class_names, num_normal=10, num_pneumonia=10):
    """
    Display images with balanced true labels (Normal and Pneumonia).
    Highlight incorrect predictions in red.
    """
    model.eval()  # Set the model to evaluation mode
    normal_images = []
    pneumonia_images = []

    # Gather predictions for "Normal" and "Pneumonia" separately
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predictions = torch.max(outputs, 1)

            for i in range(images.size(0)):
                # Convert image tensor to numpy array for display
                image = images[i].cpu().numpy().transpose(1, 2, 0)
                if image.shape[-1] == 1:  # Grayscale image
                    image = image.squeeze(-1)

                true_label = labels[i].item()
                pred_label = predictions[i].item()
                label_dict = {
                    "image": image,
                    "true_label": class_names[true_label],
                    "pred_label": class_names[pred_label],
                    "correct": true_label == pred_label,
                }

                # Collect images based on true labels
                if true_label == 0 and len(normal_images) < num_normal:
                    normal_images.append(label_dict)
                elif true_label == 1 and len(pneumonia_images) < num_pneumonia:
                    pneumonia_images.append(label_dict)

            # Break the loop if we have enough images
            if len(normal_images) >= num_normal and len(pneumonia_images) >= num_pneumonia:
                break

    # Combine images for display
    images_to_display = normal_images + pneumonia_images
    rows, cols = 4, 5  # Grid size
    fig, axes = plt.subplots(rows, cols, figsize=(15, 12))

    for idx, ax in enumerate(axes.flat):
        if idx < len(images_to_display):
            img_dict = images_to_display[idx]
            image = img_dict["image"]
            true_label = img_dict["true_label"]
            pred_label = img_dict["pred_label"]
            correct = img_dict["correct"]

            # Title with green for correct, red for incorrect
            title_color = "green" if correct else "red"
            ax.imshow(image, cmap="gray" if image.ndim == 2 else None)
            ax.set_title(f"True: {true_label}\nPred: {pred_label}", color=title_color)
            ax.axis("off")
        else:
            ax.axis("off")  # Empty cells

    plt.tight_layout()
    plt.show()

# Show predictions for Custom CNN
#print("Balanced Predictions from Custom CNN:")
#show_balanced_predictions(model_from_scratch, test_loader_cnn, class_names=["Normal", "Pneumonia"], num_normal=10, num_pneumonia=10)

# Show predictions for Pretrained ResNet18
print("Balanced Predictions from Pretrained ResNet18:")
show_balanced_predictions(resnet18, test_loader_resnet, class_names=["Normal", "Pneumonia"], num_normal=10, num_pneumonia=10)

!pip install captum

from captum.attr import GuidedGradCam, LayerGradCam
from captum.attr import visualization as viz

target_layer = resnet18.layer4[-1]  # Select the last convolutional layer of ResNet18

gradcam = LayerGradCam(resnet18, target_layer)

input_image, label = next(iter(test_loader_resnet)) # Get a sample input from the test loader
input_image = input_image[0].unsqueeze(0).to(device) # Select the first image and move it to the device
attributions = gradcam.attribute(input_image, target=label[0].item(), relu_attributions=True)

viz.visualize_image_attr(attributions[0].cpu().permute(1, 2, 0).detach().numpy(),
                         input_image[0].cpu().permute(1, 2, 0).detach().numpy(),
                         method="heat_map",
                         sign="positive",
                         show_colorbar=True,
                         title="Grad-CAM")



def visualize_gradcam_multiple_images(model, test_loader, target_layer, num_images_per_class=5):
  """Visualizes Grad-CAM for multiple images from different classes."""
  gradcam = LayerGradCam(model, target_layer)
  class_names = ["Normal", "Pneumonia"]

  images_by_class = {0: [], 1: []}  # Store images for each class

  # Collect images for each class
  for images, labels in test_loader:
    for i in range(images.size(0)):
      class_idx = labels[i].item()
      if len(images_by_class[class_idx]) < num_images_per_class:
        images_by_class[class_idx].append(images[i].unsqueeze(0))

    if all(len(images_by_class[class_idx]) >= num_images_per_class for class_idx in images_by_class):
      break  # Stop collecting if enough images are found

  # Visualize Grad-CAM for collected images
  for class_idx in images_by_class:
    for image in images_by_class[class_idx]:
      image = image.to(device)
      attributions = gradcam.attribute(image, target=class_idx, relu_attributions=True)

      viz.visualize_image_attr(attributions[0].cpu().permute(1, 2, 0).detach().numpy(),
                              image[0].cpu().permute(1, 2, 0).detach().numpy(),
                              method="heat_map",
                              sign="positive",
                              show_colorbar=True,
                              title=f"Grad-CAM - {class_names[class_idx]}",
                              cmap='Reds') # Red colormap

# Call the function to visualize
visualize_gradcam_multiple_images(resnet18, test_loader_resnet, target_layer)



